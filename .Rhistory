library(ggplot2)
ggplot(delay, aes(dist, delay)) +
geom_point(aes(size = count), alpha = 1/2) +
geom_smooth() +
scale_size_area(max_size = 2)
#Window Functions - dplyr window functions are also supported, for example:
batting_tbl %>%
select(playerID, yearID, teamID, G, AB:H) %>%
arrange(playerID, yearID, teamID) %>%
group_by(playerID) %>%
filter(min_rank(desc(H)) <= 2 & H > 0)
#Using SQL
library(DBI)
iris_preview <- dbGetQuery(sc, "SELECT * FROM iris LIMIT 10")
# Machine Learning and Spark MLlib
# In this example we’ll use ml_linear_regression to fit a linear regression model.
# We’ll use the built-in mtcars dataset, and see if we can predict a car’s fuel consumption (mpg) based on its weight (wt) and the number of cylinders the engine contains (cyl).
# We’ll assume in each case that the relationship between mpg and each of our features is linear.
# copy mtcars into spark
mtcars_tbl <- copy_to(sc, mtcars)
# transform our data set, and then partition into 'training', 'test'
partitions <- mtcars_tbl %>%
filter(hp >= 100) %>%
mutate(cyl8 = cyl == 8) %>%
sdf_partition(training = 0.5, test = 0.5, seed = 1099)
# fit a linear model to the training dataset
fit <- partitions$training %>%
ml_linear_regression(response = "mpg", features = c("wt", "cyl"))
# For linear regression models produced by Spark, we can use summary() to learn a bit more about the quality of our fit,
# and the statistical significance of each of our predictors.
summary(fit)
Welcome!
Here you will find daily news and tutorials about R, contributed by over 573 bloggers.
There are many ways to follow us -
By e-mail:
On Facebook:
If you are an R blogger yourself you are invited to add your own R content feed to this site (Non-English R bloggers should add themselves- here)
RSS Jobs for R-users
Data Analyst
Data Scientist for Madlan @ Tel Aviv, Israel
Bioinformatics Specialist @ San Francisco, U.S.
Postdoctoral Scholar @ San Francisco, U.S.
RISK ANALYSIS OFFICER / DATA MANAGER @ Paris, France
Popular Searches
web scraping
heatmap
twitter
maps
time series
boxplot
animation
Shiny
how to import image file to R
hadoop
ggplot2
trading
LaTeX
finance
eclipse
quantmod
googlevis
sql
excel
PCA
knitr
ggplot
RStudio
market research
rattle
regression
coplot
map
tutorial
Rcmdr
Recent Posts
sparklyr — R interface for Apache Spark
Fitting a distribution in Stan from scratch
2016 UK Tour
Quick wordclouds from PubMed abstracts – using PMID lists in R
Introduction to BiclustGUI
A book on RStan in Japanese: Bayesian Statistical Modeling Using Stan and R (Wonderful R, Volume 2)
Upgrading to plotly 4.0 (and above)
Replicating Plots – Boxplot Exercises
Machine Learning for Drug Adverse Event Discovery
When Trump visits… tweets from his trip to Mexico
Better Model Selection for Evolving Models
The biggest liars in US politics
FileTable and storing graphs from Microsoft R Server
Re-introducing Radiant: A shiny interface for R
tint 0.0.1: Tint Is Not Tufte
Other sites
Jobs for R-users
SAS blogs
sparklyr — R interface for Apache Spark
September 27, 2016
By jjallaire
inShare43
(This article was first published on RStudio Blog, and kindly contributed to R-bloggers)
We’re excited today to announce sparklyr, a new package that provides an interface between R and Apache Spark.
Over the past couple of years we’ve heard time and time again that people want a native dplyr interface to Spark, so we built one! sparklyr also provides interfaces to Spark’s distributed machine learning algorithms and much more. Highlights include:
Interactively manipulate Spark data using both dplyr and SQL (via DBI).
Filter and aggregate Spark datasets then bring them into R for analysis and visualization.
Orchestrate distributed machine learning from R using either Spark MLlib or H2O SparkingWater.
Create extensions that call the full Spark API and provide interfaces to Spark packages.
Integrated support for establishing Spark connections and browsing Spark data frames within the RStudio IDE.
We’re also excited to be working with several industry partners. IBM is incorporating sparklyr into their Data Science Experience, Cloudera is working with us to ensure that sparklyr meets the requirements of their enterprise customers, and H2O has provided an integration between sparklyr and H2O Sparkling Water.
Getting Started
You can install sparklyr from CRAN as follows:
install.packages("sparklyr")
You should also install a local version of Spark for development purposes:
library(sparklyr)
spark_install(version = "1.6.2")
library(sparklyr)
sc <- spark_connect(master = "local")
spark_disconnect(sc)
library(sparklyr)
sc <- spark_connect(master = "local")
#You can install sparklyr from CRAN as follows:
#install.packages("sparklyr")
#library(sparklyr) #Load the Library
#You should also install a local version of Spark for development purposes:
#spark_install(version = "2.0.0")
#Connecting to Spark - Not always so comment it
#sc <- spark_connect(master = "local")
library(sparklyr)
#Reading Data
library(dplyr)
iris_tbl <- copy_to(sc, iris)
flights_tbl <- copy_to(sc, nycflights13::flights, "flights")
batting_tbl <- copy_to(sc, Lahman::Batting, "batting")
#Using dplyr
# filter by departure delay
flights_tbl %>% filter(dep_delay == 2)
delay <- flights_tbl %>%
group_by(tailnum) %>%
summarise(count = n(), dist = mean(distance), delay = mean(arr_delay)) %>%
filter(count > 20, dist < 2000, !is.na(delay)) %>%
collect()
# plot delays
library(ggplot2)
ggplot(delay, aes(dist, delay)) +
geom_point(aes(size = count), alpha = 1/2) +
geom_smooth() +
scale_size_area(max_size = 2)
#Window Functions - dplyr window functions are also supported, for example:
batting_tbl %>%
select(playerID, yearID, teamID, G, AB:H) %>%
arrange(playerID, yearID, teamID) %>%
group_by(playerID) %>%
filter(min_rank(desc(H)) <= 2 & H > 0)
#Using SQL
library(DBI)
iris_preview <- dbGetQuery(sc, "SELECT * FROM iris LIMIT 10")
# Machine Learning and Spark MLlib
# In this example we’ll use ml_linear_regression to fit a linear regression model.
# We’ll use the built-in mtcars dataset, and see if we can predict a car’s fuel consumption (mpg) based on its weight (wt) and the number of cylinders the engine contains (cyl).
# We’ll assume in each case that the relationship between mpg and each of our features is linear.
# copy mtcars into spark
mtcars_tbl <- copy_to(sc, mtcars)
# transform our data set, and then partition into 'training', 'test'
partitions <- mtcars_tbl %>%
filter(hp >= 100) %>%
mutate(cyl8 = cyl == 8) %>%
sdf_partition(training = 0.5, test = 0.5, seed = 1099)
# fit a linear model to the training dataset
fit <- partitions$training %>%
ml_linear_regression(response = "mpg", features = c("wt", "cyl"))
# For linear regression models produced by Spark, we can use summary() to learn a bit more about the quality of our fit,
# and the statistical significance of each of our predictors.
summary(fit)
Welcome!
Here you will find daily news and tutorials about R, contributed by over 573 bloggers.
There are many ways to follow us -
By e-mail:
On Facebook:
If you are an R blogger yourself you are invited to add your own R content feed to this site (Non-English R bloggers should add themselves- here)
RSS Jobs for R-users
Data Analyst
Data Scientist for Madlan @ Tel Aviv, Israel
Bioinformatics Specialist @ San Francisco, U.S.
Postdoctoral Scholar @ San Francisco, U.S.
RISK ANALYSIS OFFICER / DATA MANAGER @ Paris, France
Popular Searches
web scraping
heatmap
twitter
maps
time series
boxplot
animation
Shiny
how to import image file to R
hadoop
ggplot2
trading
LaTeX
finance
eclipse
quantmod
googlevis
sql
excel
PCA
knitr
ggplot
RStudio
market research
rattle
regression
coplot
map
tutorial
Rcmdr
Recent Posts
sparklyr — R interface for Apache Spark
Fitting a distribution in Stan from scratch
2016 UK Tour
Quick wordclouds from PubMed abstracts – using PMID lists in R
Introduction to BiclustGUI
A book on RStan in Japanese: Bayesian Statistical Modeling Using Stan and R (Wonderful R, Volume 2)
Upgrading to plotly 4.0 (and above)
Replicating Plots – Boxplot Exercises
Machine Learning for Drug Adverse Event Discovery
When Trump visits… tweets from his trip to Mexico
Better Model Selection for Evolving Models
The biggest liars in US politics
FileTable and storing graphs from Microsoft R Server
Re-introducing Radiant: A shiny interface for R
tint 0.0.1: Tint Is Not Tufte
Other sites
Jobs for R-users
SAS blogs
sparklyr — R interface for Apache Spark
September 27, 2016
By jjallaire
inShare43
(This article was first published on RStudio Blog, and kindly contributed to R-bloggers)
We’re excited today to announce sparklyr, a new package that provides an interface between R and Apache Spark.
Over the past couple of years we’ve heard time and time again that people want a native dplyr interface to Spark, so we built one! sparklyr also provides interfaces to Spark’s distributed machine learning algorithms and much more. Highlights include:
Interactively manipulate Spark data using both dplyr and SQL (via DBI).
Filter and aggregate Spark datasets then bring them into R for analysis and visualization.
Orchestrate distributed machine learning from R using either Spark MLlib or H2O SparkingWater.
Create extensions that call the full Spark API and provide interfaces to Spark packages.
Integrated support for establishing Spark connections and browsing Spark data frames within the RStudio IDE.
We’re also excited to be working with several industry partners. IBM is incorporating sparklyr into their Data Science Experience, Cloudera is working with us to ensure that sparklyr meets the requirements of their enterprise customers, and H2O has provided an integration between sparklyr and H2O Sparkling Water.
Getting Started
You can install sparklyr from CRAN as follows:
install.packages("sparklyr")
You should also install a local version of Spark for development purposes:
library(sparklyr)
spark_install(version = "1.6.2")
spark_disconnect(sc)
library(sparklyr)
sc <- spark_connect(master = "local")
library(dplyr)
library(dplyr)
iris_tbl <- copy_to(sc, iris)
flights_tbl <- copy_to(sc, nycflights13::flights, "flights")
batting_tbl <- copy_to(sc, Lahman::Batting, "batting")
flights_tbl %>% filter(dep_delay == 2)
library(nycflights13)
install.packages(nycflights13)
mtcars_tbl <- copy_to(sc, mtcars)
partitions <- mtcars_tbl %>%
filter(hp >= 100) %>%
mutate(cyl8 = cyl == 8) %>%
sdf_partition(training = 0.5, test = 0.5, seed = 1099)
fit <- partitions$training %>%
ml_linear_regression(response = "mpg", features = c("wt", "cyl"))
summary(fit)
training <- as_h2o_frame(partitions$training)
test <- as_h2o_frame(partitions$test)
detach("package:dplyr", unload=TRUE)
spark_disconnect(sc)
library(sparklyr)
sc <- spark_connect(master = "local")
mtcars_tbl <- copy_to(sc, mtcars)
mtcars_tbl <- copy_to(sc, mtcars)
library(sparklyr)
sc <- spark_connect(master = "local")
mtcars_tbl <- copy_to(sc, mtcars)
library("dplyr", lib.loc="/usr/lib64/R/library")
mtcars_tbl <- copy_to(sc, mtcars)
load("/root/Downloads/etsfc")
write.csv(mydata, "mydets.csv")
mydata$TS = unlist(mydata$TS)
View(mydata)
data()
install.packages("titanic")
library("titanic", lib.loc="/usr/lib64/R/library")
data()
data("Titanic")
load(Titanic)
load("Titanic")
mydata <- Titanic
mydata <- Titanic
Titanic
View(Titanic)
kmeans(Titanic, centers = 5)
setwd("/root/git/RelianceCableFaults")
# Install and loading libraries
if(!require(forecast)){
install.packages("forecast")
}
library(forecast)
# loading Data
cable_fault_data <- read.csv("Cable Faults.csv")
# Function for forecasting cable faults
Cable_Fault_FC <- function(type = NULL, zone = NULL,horizon = NULL){
mydata <- cable_fault_data[cable_fault_data$Zone == zone & cable_fault_data$Type == type,]
# Convering Month variable in date format
mydata$Month <- paste0("01-",mydata$Month)
mydata$Month <- as.Date(mydata$Month, format = "%d-%b-%y")
# Ordering Data in ascending order
mydata <- mydata[order(mydata$Month,decreasing = F),]
# determine last month
last_month <- as.numeric(format(tail(mydata$Month,1),"%m"))
last_year <- as.numeric(format(tail(mydata$Month,1),"%Y"))
# creating time series
myts <-  ts(mydata$Cases,end = c(last_year,last_month), frequency = 12)
# detecting outliers
outliers <- tsoutliers(myts)
# replacement for outliers
myts[outliers$index] <- outliers$replacements
# fitting ARIMA model
fit_arima <- auto.arima(myts)
# fitting exponential smoothing model
fit_expo <- ets(myts)
# Compare accuracy
acc_arima <- accuracy(fit_arima)[,"RMSE"]
acc_expo <- accuracy(fit_expo)[,"RMSE"]
# forecasting with best method
if( acc_arima < acc_expo){
FC <- forecast(fit_arima, as.numeric(horizon))
FC <- FC$mean
} else {
FC <- forecast(fit_expo, as.numeric(horizon))
FC <- FC$mean
}
# output
return (FC)
}
# running forecasting function
# input the values for the variables
message("Enter the  type of the Fault (All Fault/HT Fault/LT Fault)...")
type <- "All Fault" #readLines(n = 1)
message("Enter the name of zone (SOUTH/SOUTH CENTRAL/CENTRAL/NORTH/EAST TOTAL/TOTAL)...")
zone <- "SOUTH" #readLines(n = 1)
message("Enter the number of months fore forecasting(1/2/3/4/.....)...")
horizon <- readLines(n = 1)
# Forecasting using  defined  function :Cable_Fault_FC
FC <- Cable_Fault_FC(type = type,zone = zone,horizon = horizon)
print(FC)
setwd("/root/git/RelianceCableFaults")
# Install and loading libraries
if(!require(forecast)){
install.packages("forecast")
}
library(forecast)
# loading Data
cable_fault_data <- read.csv("Cable Faults.csv")
# Function for forecasting cable faults
Cable_Fault_FC <- function(type = NULL, zone = NULL,horizon = NULL){
mydata <- cable_fault_data[cable_fault_data$Zone == zone & cable_fault_data$Type == type,]
# Convering Month variable in date format
mydata$Month <- paste0("01-",mydata$Month)
mydata$Month <- as.Date(mydata$Month, format = "%d-%b-%y")
# Ordering Data in ascending order
mydata <- mydata[order(mydata$Month,decreasing = F),]
# determine last month
last_month <- as.numeric(format(tail(mydata$Month,1),"%m"))
last_year <- as.numeric(format(tail(mydata$Month,1),"%Y"))
# creating time series
myts <-  ts(mydata$Cases,end = c(last_year,last_month), frequency = 12)
# detecting outliers
outliers <- tsoutliers(myts)
# replacement for outliers
myts[outliers$index] <- outliers$replacements
# fitting ARIMA model
fit_arima <- auto.arima(myts)
# fitting exponential smoothing model
fit_expo <- ets(myts)
# Compare accuracy
acc_arima <- accuracy(fit_arima)[,"RMSE"]
acc_expo <- accuracy(fit_expo)[,"RMSE"]
# forecasting with best method
if( acc_arima < acc_expo){
FC <- forecast(fit_arima, as.numeric(horizon))
FC <- FC$mean
} else {
FC <- forecast(fit_expo, as.numeric(horizon))
FC <- FC$mean
}
# output
return (FC)
}
# running forecasting function
# input the values for the variables
message("Enter the  type of the Fault (All Fault/HT Fault/LT Fault)...")
type <- "All Fault" #readLines(n = 1)
message("Enter the name of zone (SOUTH/SOUTH CENTRAL/CENTRAL/NORTH/EAST TOTAL/TOTAL)...")
zone <- "SOUTH" #readLines(n = 1)
message("Enter the number of months fore forecasting(1/2/3/4/.....)...")
horizon <- 4 #readLines(n = 1)
# Forecasting using  defined  function :Cable_Fault_FC
FC <- Cable_Fault_FC(type = type,zone = zone,horizon = horizon)
print(FC)
View(cable_fault_data)
setwd("/root/git/RelianceCableFaults")
# Install and loading libraries
if(!require(forecast)){
install.packages("forecast")
}
library(forecast)
# loading Data
cable_fault_data <- read.csv("Cable Faults.csv")
# Function for forecasting cable faults
Cable_Fault_FC <- function(type = NULL, zone = NULL,horizon = NULL){
mydata <- cable_fault_data[cable_fault_data$Zone == zone & cable_fault_data$Type == type,]
# Convering Month variable in date format
mydata$Month <- paste0("01-",mydata$Month)
mydata$Month <- as.Date(mydata$Month, format = "%d-%b-%y")
# Ordering Data in ascending order
mydata <- mydata[order(mydata$Month,decreasing = F),]
# determine last month
last_month <- as.numeric(format(tail(mydata$Month,1),"%m"))
last_year <- as.numeric(format(tail(mydata$Month,1),"%Y"))
# creating time series
myts <-  ts(mydata$Cases,end = c(last_year,last_month), frequency = 12)
# detecting outliers
outliers <- tsoutliers(myts)
# replacement for outliers
myts[outliers$index] <- outliers$replacements
# fitting ARIMA model
fit_arima <- auto.arima(myts)
# fitting exponential smoothing model
fit_expo <- ets(myts)
# Compare accuracy
acc_arima <- accuracy(fit_arima)[,"RMSE"]
acc_expo <- accuracy(fit_expo)[,"RMSE"]
# forecasting with best method
if( acc_arima < acc_expo){
FC <- forecast(fit_arima, as.numeric(horizon))
FC <- FC$mean
} else {
FC <- forecast(fit_expo, as.numeric(horizon))
FC <- FC$mean
}
# output
return (FC)
}
# running forecasting function
# input the values for the variables
message("Enter the  type of the Fault (All Fault/HT Fault/LT Fault)...")
type <- "All Fault" #readLines(n = 1)
message("Enter the name of zone (SOUTH/SOUTH CENTRAL/CENTRAL/NORTH/EAST TOTAL/TOTAL)...")
zone <- "SOUTH" #readLines(n = 1)
message("Enter the number of months fore forecasting(1/2/3/4/.....)...")
horizon <- 4 #readLines(n = 1)
# Forecasting using  defined  function :Cable_Fault_FC
FC <- Cable_Fault_FC(type = type,zone = zone,horizon = horizon)
print(FC)
View(Cable_Fault_FC)
fit_expo <- ets(myts)
setwd("/root/git/RelianceCableFaults")
if(!require(forecast)){
install.packages("forecast")
}
library(forecast)
cable_fault_data <- read.csv("Cable Faults.csv")
Cable_Fault_FC <- function(type = NULL, zone = NULL,horizon = NULL){
mydata <- cable_fault_data[cable_fault_data$Zone == zone & cable_fault_data$Type == type,]
# Convering Month variable in date format
mydata$Month <- paste0("01-",mydata$Month)
mydata$Month <- as.Date(mydata$Month, format = "%d-%b-%y")
# Ordering Data in ascending order
mydata <- mydata[order(mydata$Month,decreasing = F),]
# determine last month
last_month <- as.numeric(format(tail(mydata$Month,1),"%m"))
last_year <- as.numeric(format(tail(mydata$Month,1),"%Y"))
# creating time series
myts <-  ts(mydata$Cases,end = c(last_year,last_month), frequency = 12)
# detecting outliers
outliers <- tsoutliers(myts)
# replacement for outliers
myts[outliers$index] <- outliers$replacements
# fitting ARIMA model
fit_arima <- auto.arima(myts)
# fitting exponential smoothing model
fit_expo <- ets(myts)
# Compare accuracy
acc_arima <- accuracy(fit_arima)[,"RMSE"]
acc_expo <- accuracy(fit_expo)[,"RMSE"]
# forecasting with best method
if( acc_arima < acc_expo){
FC <- forecast(fit_arima, as.numeric(horizon))
FC <- FC$mean
} else {
FC <- forecast(fit_expo, as.numeric(horizon))
FC <- FC$mean
}
# output
return (FC)
}
message("Enter the  type of the Fault (All Fault/HT Fault/LT Fault)...")
type <- "All Fault" #readLines(n = 1)
message("Enter the name of zone (SOUTH/SOUTH CENTRAL/CENTRAL/NORTH/EAST TOTAL/TOTAL)...")
zone <- "SOUTH" #readLines(n = 1)
message("Enter the number of months fore forecasting(1/2/3/4/.....)...")
horizon <- 4 #readLines(n = 1)
FC <- Cable_Fault_FC(type = type,zone = zone,horizon = horizon)
print(FC)
